{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Finding Similar Items: Textually Similar Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to implement shingling, minhashing and LSH algorithms in order to compare text-based documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 5: '\t' expected after '\"'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test one two three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test one two four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything from the weather, staff, food, prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We full enjoyed the place, and facilities.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks for the \"\"cidreira\"\" and \"\"madalenas\"\" ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0                                 Test one two three\n",
       "1                                  Test one two four\n",
       "2  Everything from the weather, staff, food, prop...\n",
       "3         We full enjoyed the place, and facilities.\n",
       "4  Thanks for the \"\"cidreira\"\" and \"\"madalenas\"\" ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import dataset\n",
    "df = pd.read_csv('dataset-CalheirosMoroRita-2017.csv',  error_bad_lines=False, engine='python', sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test one two three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test one two four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything from the weather staff food propert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We full enjoyed the place and facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks for the cidreira and madalenas tea at r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0                                 Test one two three\n",
       "1                                  Test one two four\n",
       "2  Everything from the weather staff food propert...\n",
       "3           We full enjoyed the place and facilities\n",
       "4  Thanks for the cidreira and madalenas tea at r..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean the files from puncuation signs, spaces and newlines\n",
    "df['Review'] = df['Review'].str.replace(r'[^\\w\\s\\n]', '')\n",
    "df['Review'] = df['Review'].str.replace('\\\"', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shingling phase\n",
    "\n",
    "Here we perform the shinglign phase - Divide the documents in word-touples of size in the variable `shingle_size`\n",
    "\n",
    "1. Assign shingling size\n",
    "1. Split the documents in list of words\n",
    "1. Group words in tuples of `shingle_size`\n",
    "1. Transform the list of tuples in sets of tuples to avoid duplication and put in in `shingles` column in the dataframe\n",
    "1. Create a new column with a hashed version of shingles:\n",
    "    * join the tuples into a string\n",
    "    * hash the byte-encoded string using `s_hash` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>shingles</th>\n",
       "      <th>hashes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test one two three</td>\n",
       "      <td>[(Test, one, two), (one, two, three)]</td>\n",
       "      <td>[2080834851, 2015744983]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test one two four</td>\n",
       "      <td>[(one, two, four), (Test, one, two)]</td>\n",
       "      <td>[515743642, 2080834851]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything from the weather staff food propert...</td>\n",
       "      <td>[(dcor, spa, rooms), (spa, rooms, and), (the, ...</td>\n",
       "      <td>[2981500306, 184128390, 3069561215, 1132586348...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We full enjoyed the place and facilities</td>\n",
       "      <td>[(full, enjoyed, the), (We, full, enjoyed), (t...</td>\n",
       "      <td>[2575702922, 3949555090, 3903531572]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks for the cidreira and madalenas tea at r...</td>\n",
       "      <td>[(and, madalenas, tea), (for, the, cidreira), ...</td>\n",
       "      <td>[1353929374, 1824094365, 813168974, 2672588445]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0                                 Test one two three   \n",
       "1                                  Test one two four   \n",
       "2  Everything from the weather staff food propert...   \n",
       "3           We full enjoyed the place and facilities   \n",
       "4  Thanks for the cidreira and madalenas tea at r...   \n",
       "\n",
       "                                            shingles  \\\n",
       "0              [(Test, one, two), (one, two, three)]   \n",
       "1               [(one, two, four), (Test, one, two)]   \n",
       "2  [(dcor, spa, rooms), (spa, rooms, and), (the, ...   \n",
       "3  [(full, enjoyed, the), (We, full, enjoyed), (t...   \n",
       "4  [(and, madalenas, tea), (for, the, cidreira), ...   \n",
       "\n",
       "                                              hashes  \n",
       "0                           [2080834851, 2015744983]  \n",
       "1                            [515743642, 2080834851]  \n",
       "2  [2981500306, 184128390, 3069561215, 1132586348...  \n",
       "3               [2575702922, 3949555090, 3903531572]  \n",
       "4    [1353929374, 1824094365, 813168974, 2672588445]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shingling phase\n",
    "shingle_size = 3\n",
    "\n",
    "#method to group words in tupples of shingle_size size\n",
    "def shingles(words, n = shingle_size):\n",
    "    return [words[i:i+n] for i in range(len(words) - n + 1) if len(words[i]) < 5]\n",
    "\n",
    "df_shingled = df.copy()\n",
    "df_shingled['Review'] = df.Review.map(lambda x : x.split())\n",
    "df['shingles'] = df_shingled.Review.map(shingles)\n",
    "df['shingles'] = df.shingles.map(lambda shingles : [x for x in set(tuple(x) for x in shingles)])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>shingles</th>\n",
       "      <th>hashes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test one two three</td>\n",
       "      <td>[(Test, one, two), (one, two, three)]</td>\n",
       "      <td>[2080834851, 2015744983]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test one two four</td>\n",
       "      <td>[(one, two, four), (Test, one, two)]</td>\n",
       "      <td>[515743642, 2080834851]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything from the weather staff food propert...</td>\n",
       "      <td>[(dcor, spa, rooms), (spa, rooms, and), (the, ...</td>\n",
       "      <td>[2981500306, 184128390, 3069561215, 1132586348...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We full enjoyed the place and facilities</td>\n",
       "      <td>[(full, enjoyed, the), (We, full, enjoyed), (t...</td>\n",
       "      <td>[2575702922, 3949555090, 3903531572]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks for the cidreira and madalenas tea at r...</td>\n",
       "      <td>[(and, madalenas, tea), (for, the, cidreira), ...</td>\n",
       "      <td>[1353929374, 1824094365, 813168974, 2672588445]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0                                 Test one two three   \n",
       "1                                  Test one two four   \n",
       "2  Everything from the weather staff food propert...   \n",
       "3           We full enjoyed the place and facilities   \n",
       "4  Thanks for the cidreira and madalenas tea at r...   \n",
       "\n",
       "                                            shingles  \\\n",
       "0              [(Test, one, two), (one, two, three)]   \n",
       "1               [(one, two, four), (Test, one, two)]   \n",
       "2  [(dcor, spa, rooms), (spa, rooms, and), (the, ...   \n",
       "3  [(full, enjoyed, the), (We, full, enjoyed), (t...   \n",
       "4  [(and, madalenas, tea), (for, the, cidreira), ...   \n",
       "\n",
       "                                              hashes  \n",
       "0                           [2080834851, 2015744983]  \n",
       "1                            [515743642, 2080834851]  \n",
       "2  [2981500306, 184128390, 3069561215, 1132586348...  \n",
       "3               [2575702922, 3949555090, 3903531572]  \n",
       "4    [1353929374, 1824094365, 813168974, 2672588445]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import binascii\n",
    "\n",
    "def s_hash(shingle):\n",
    "    return binascii.crc32(shingle) & 0xffffffff\n",
    "\n",
    "df['hashes'] = df.shingles.map(lambda shingles: [s_hash((\" \".join(word for word in shingle)).encode()) for shingle in shingles])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinHash phase\n",
    "In this phase we calculate the minhashes for each document.\n",
    "\n",
    "1. Set the number of hashes per document in `numhashes`\n",
    "2. Generate the two lists of coefficients for the minhash functions\n",
    "3. Create the signature lists using generated coefficients and save it to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient array created for 10numhashes\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#number of hashesh per document\n",
    "numhashes = 10\n",
    "\n",
    "#we took the max integer as the upper limit of the minhashes\n",
    "max_shingle_id = 2**32-1\n",
    "# a prime number bigger than maxInt\n",
    "big_prime = 4294967311\n",
    "\n",
    "#generation of random coeffiencents for all k ax+b functions \n",
    "def rand_coefficients(k):\n",
    "    rand_coeff = []  \n",
    "    while k > 0:\n",
    "        randIndex = random.randint(0, max_shingle_id) \n",
    "        while randIndex in rand_coeff:\n",
    "                randIndex = random.randint(0, max_shingle_id) \n",
    "        rand_coeff.append(randIndex)\n",
    "        k = k - 1\n",
    "    return rand_coeff\n",
    "\n",
    "\n",
    "#generate a for ax+b\n",
    "coeff1 = rand_coefficients(numhashes)\n",
    "#generate b for ax+b\n",
    "coeff2 = rand_coefficients(numhashes)\n",
    "print(\"coefficient array created for \" + str(numhashes) + \"numhashes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>shingles</th>\n",
       "      <th>hashes</th>\n",
       "      <th>signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test one two three</td>\n",
       "      <td>[(Test, one, two), (one, two, three)]</td>\n",
       "      <td>[2080834851, 2015744983]</td>\n",
       "      <td>[1877537571, 1759969086, 3674356561, 670456082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test one two four</td>\n",
       "      <td>[(one, two, four), (Test, one, two)]</td>\n",
       "      <td>[515743642, 2080834851]</td>\n",
       "      <td>[1374638825, 1369335934, 3283383602, 670456082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything from the weather staff food propert...</td>\n",
       "      <td>[(dcor, spa, rooms), (spa, rooms, and), (the, ...</td>\n",
       "      <td>[2981500306, 184128390, 3069561215, 1132586348...</td>\n",
       "      <td>[1034231098, 144710362, 989412207, 41469827, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We full enjoyed the place and facilities</td>\n",
       "      <td>[(full, enjoyed, the), (We, full, enjoyed), (t...</td>\n",
       "      <td>[2575702922, 3949555090, 3903531572]</td>\n",
       "      <td>[1035613178, 1079444216, 159366595, 922632930,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks for the cidreira and madalenas tea at r...</td>\n",
       "      <td>[(and, madalenas, tea), (for, the, cidreira), ...</td>\n",
       "      <td>[1353929374, 1824094365, 813168974, 2672588445]</td>\n",
       "      <td>[262562206, 599345854, 670457660, 844186963, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0                                 Test one two three   \n",
       "1                                  Test one two four   \n",
       "2  Everything from the weather staff food propert...   \n",
       "3           We full enjoyed the place and facilities   \n",
       "4  Thanks for the cidreira and madalenas tea at r...   \n",
       "\n",
       "                                            shingles  \\\n",
       "0              [(Test, one, two), (one, two, three)]   \n",
       "1               [(one, two, four), (Test, one, two)]   \n",
       "2  [(dcor, spa, rooms), (spa, rooms, and), (the, ...   \n",
       "3  [(full, enjoyed, the), (We, full, enjoyed), (t...   \n",
       "4  [(and, madalenas, tea), (for, the, cidreira), ...   \n",
       "\n",
       "                                              hashes  \\\n",
       "0                           [2080834851, 2015744983]   \n",
       "1                            [515743642, 2080834851]   \n",
       "2  [2981500306, 184128390, 3069561215, 1132586348...   \n",
       "3               [2575702922, 3949555090, 3903531572]   \n",
       "4    [1353929374, 1824094365, 813168974, 2672588445]   \n",
       "\n",
       "                                           signature  \n",
       "0  [1877537571, 1759969086, 3674356561, 670456082...  \n",
       "1  [1374638825, 1369335934, 3283383602, 670456082...  \n",
       "2  [1034231098, 144710362, 989412207, 41469827, 7...  \n",
       "3  [1035613178, 1079444216, 159366595, 922632930,...  \n",
       "4  [262562206, 599345854, 670457660, 844186963, 1...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter datafram to eliminate empty hash lists\n",
    "df = df[df.hashes.apply(len) > 0]\n",
    "\n",
    "#create a column of empty lists\n",
    "df[\"signature\"] = np.empty((len(df),0)).tolist()\n",
    "\n",
    "#loop over hash functions\n",
    "def min_hash(row):\n",
    "    signature = []\n",
    "    f_results = []\n",
    "    #apply (ax+b)%c for every document using above generated coefficients to generate signatures\n",
    "    for i in range(numhashes):\n",
    "        f_results = [((coeff1[i] * h  + coeff2[i]) % big_prime) for h in  row.hashes]\n",
    "        #select the minimum of the results\n",
    "        signature.append(min(f_results))\n",
    "    row.signature = signature\n",
    "    return row\n",
    "\n",
    "#apply the min_hash on the dataframe\n",
    "df = df.apply(min_hash, axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement jaccard similarity\n",
    "def jaccard(sig1, sig2):\n",
    "    return len(set(sig1).intersection(set(sig2)))/len(set(sig1).union(set(sig2)))\n",
    "\n",
    "#function to compare two signature on similarity\n",
    "def min_hash_sim(sig1, sig2):\n",
    "    count = 0\n",
    "    for i in range(numhashes):\n",
    "        if (sig1[i] == sig2[i]):\n",
    "            count += 1\n",
    "    return count/numhashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fast testing the min_hash_sim on the first two document\n",
    "set(df.signature.iloc[0]).union(df.signature.iloc[1])\n",
    "set(df.signature.iloc[0]).intersection(df.signature.iloc[1])\n",
    "min_hash_sim(df.signature.iloc[1], df.signature.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `threshold` is used to set the lowest bownd for similarity.\n",
    "We iterate over all pairs of documents and select only document pairs that have the similarity score above the set threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  and  1 :  0.3\n",
      "3  and  135 :  0.1\n",
      "8  and  12 :  0.2\n",
      "8  and  20 :  0.1\n",
      "8  and  44 :  0.4\n",
      "8  and  45 :  0.1\n",
      "8  and  50 :  0.1\n",
      "8  and  57 :  0.2\n",
      "8  and  88 :  0.3\n",
      "8  and  90 :  0.3\n",
      "8  and  92 :  0.4\n",
      "8  and  125 :  0.3\n",
      "8  and  130 :  0.3\n",
      "8  and  134 :  0.4\n",
      "8  and  146 :  0.1\n",
      "8  and  149 :  0.4\n",
      "8  and  184 :  0.2\n",
      "8  and  192 :  0.3\n",
      "8  and  225 :  0.2\n",
      "8  and  360 :  0.3\n",
      "9  and  143 :  0.2\n",
      "9  and  334 :  0.1\n",
      "10  and  67 :  0.1\n",
      "10  and  186 :  0.1\n",
      "10  and  192 :  0.1\n",
      "10  and  228 :  0.1\n",
      "10  and  229 :  0.2\n",
      "12  and  20 :  0.1\n",
      "12  and  44 :  0.2\n",
      "12  and  45 :  0.2\n",
      "12  and  50 :  0.1\n",
      "12  and  56 :  0.1\n",
      "12  and  57 :  0.1\n",
      "12  and  88 :  0.2\n",
      "12  and  90 :  0.2\n",
      "12  and  92 :  0.2\n",
      "12  and  125 :  0.2\n",
      "12  and  130 :  0.2\n",
      "12  and  134 :  0.2\n",
      "12  and  146 :  0.1\n",
      "12  and  149 :  0.2\n",
      "12  and  184 :  0.1\n",
      "12  and  192 :  0.2\n",
      "12  and  224 :  0.1\n",
      "12  and  225 :  0.1\n",
      "12  and  360 :  0.2\n",
      "13  and  46 :  0.2\n",
      "13  and  179 :  0.1\n",
      "13  and  330 :  0.3\n",
      "13  and  345 :  0.1\n",
      "13  and  366 :  0.2\n",
      "13  and  385 :  0.1\n",
      "13  and  389 :  0.2\n",
      "15  and  214 :  0.1\n",
      "15  and  387 :  0.1\n",
      "16  and  116 :  0.1\n",
      "16  and  183 :  0.1\n",
      "16  and  206 :  0.1\n",
      "16  and  252 :  0.1\n",
      "17  and  321 :  0.1\n",
      "18  and  56 :  0.1\n",
      "20  and  44 :  0.1\n",
      "20  and  45 :  0.1\n",
      "20  and  50 :  0.1\n",
      "20  and  55 :  0.1\n",
      "20  and  57 :  0.1\n",
      "20  and  88 :  0.1\n",
      "20  and  90 :  0.1\n",
      "20  and  92 :  0.1\n",
      "20  and  125 :  0.1\n",
      "20  and  130 :  0.1\n",
      "20  and  134 :  0.1\n",
      "20  and  136 :  0.1\n",
      "20  and  145 :  0.1\n",
      "20  and  146 :  0.1\n",
      "20  and  149 :  0.1\n",
      "20  and  161 :  0.1\n",
      "20  and  184 :  0.1\n",
      "20  and  192 :  0.1\n",
      "20  and  225 :  0.1\n",
      "20  and  227 :  0.1\n",
      "20  and  228 :  0.1\n",
      "20  and  304 :  0.1\n",
      "20  and  360 :  0.1\n",
      "20  and  396 :  0.1\n",
      "24  and  50 :  0.1\n",
      "24  and  53 :  0.1\n",
      "24  and  117 :  0.1\n",
      "24  and  224 :  0.1\n",
      "25  and  140 :  0.1\n",
      "25  and  144 :  0.1\n",
      "27  and  143 :  0.1\n",
      "28  and  109 :  0.1\n",
      "29  and  48 :  0.1\n",
      "29  and  141 :  0.1\n",
      "29  and  336 :  0.1\n",
      "29  and  396 :  0.1\n",
      "35  and  154 :  0.1\n",
      "35  and  157 :  0.1\n",
      "35  and  162 :  0.1\n",
      "35  and  274 :  0.1\n",
      "35  and  275 :  0.1\n",
      "35  and  281 :  0.1\n",
      "39  and  127 :  0.2\n",
      "39  and  281 :  0.1\n",
      "40  and  385 :  0.1\n",
      "42  and  98 :  0.1\n",
      "42  and  140 :  0.1\n",
      "42  and  178 :  0.1\n",
      "42  and  215 :  0.1\n",
      "44  and  45 :  0.1\n",
      "44  and  50 :  0.1\n",
      "44  and  57 :  0.2\n",
      "44  and  88 :  0.3\n",
      "44  and  90 :  0.3\n",
      "44  and  92 :  0.3\n",
      "44  and  125 :  0.3\n",
      "44  and  130 :  0.3\n",
      "44  and  134 :  0.3\n",
      "44  and  146 :  0.1\n",
      "44  and  149 :  0.3\n",
      "44  and  184 :  0.2\n",
      "44  and  192 :  0.2\n",
      "44  and  225 :  0.2\n",
      "44  and  360 :  0.3\n",
      "45  and  50 :  0.1\n",
      "45  and  52 :  0.1\n",
      "45  and  57 :  0.1\n",
      "45  and  58 :  0.1\n",
      "45  and  88 :  0.1\n",
      "45  and  90 :  0.1\n",
      "45  and  92 :  0.1\n",
      "45  and  125 :  0.1\n",
      "45  and  130 :  0.1\n",
      "45  and  134 :  0.1\n",
      "45  and  146 :  0.1\n",
      "45  and  149 :  0.1\n",
      "45  and  184 :  0.1\n",
      "45  and  192 :  0.2\n",
      "45  and  225 :  0.1\n",
      "45  and  360 :  0.1\n",
      "46  and  98 :  0.1\n",
      "46  and  179 :  0.2\n",
      "46  and  330 :  0.2\n",
      "46  and  345 :  0.1\n",
      "46  and  366 :  0.2\n",
      "46  and  385 :  0.1\n",
      "46  and  389 :  0.1\n",
      "49  and  189 :  0.1\n",
      "49  and  225 :  0.1\n",
      "49  and  270 :  0.1\n",
      "49  and  367 :  0.1\n",
      "50  and  57 :  0.2\n",
      "50  and  88 :  0.1\n",
      "50  and  90 :  0.2\n",
      "50  and  92 :  0.2\n",
      "50  and  117 :  0.1\n",
      "50  and  125 :  0.2\n",
      "50  and  130 :  0.2\n",
      "50  and  134 :  0.1\n",
      "50  and  146 :  0.1\n",
      "50  and  149 :  0.1\n",
      "50  and  184 :  0.1\n",
      "50  and  192 :  0.2\n",
      "50  and  225 :  0.1\n",
      "50  and  360 :  0.1\n",
      "52  and  396 :  0.1\n",
      "53  and  69 :  0.2\n",
      "53  and  224 :  0.1\n",
      "53  and  331 :  0.2\n",
      "55  and  84 :  0.1\n",
      "55  and  98 :  0.1\n",
      "55  and  103 :  0.1\n",
      "55  and  136 :  0.3\n",
      "55  and  137 :  0.1\n",
      "55  and  140 :  0.1\n",
      "55  and  144 :  0.3\n",
      "55  and  145 :  0.3\n",
      "55  and  186 :  0.1\n",
      "55  and  187 :  0.1\n",
      "55  and  200 :  0.1\n",
      "55  and  204 :  0.1\n",
      "55  and  215 :  0.1\n",
      "55  and  227 :  0.4\n",
      "55  and  228 :  0.3\n",
      "55  and  242 :  0.2\n",
      "55  and  245 :  0.1\n",
      "55  and  259 :  0.1\n",
      "55  and  357 :  0.1\n",
      "55  and  386 :  0.1\n",
      "55  and  396 :  0.1\n",
      "56  and  135 :  0.1\n",
      "56  and  224 :  0.1\n",
      "57  and  88 :  0.2\n",
      "57  and  90 :  0.3\n",
      "57  and  92 :  0.3\n",
      "57  and  125 :  0.3\n",
      "57  and  130 :  0.3\n",
      "57  and  134 :  0.1\n",
      "57  and  146 :  0.1\n",
      "57  and  149 :  0.1\n",
      "57  and  184 :  0.2\n",
      "57  and  192 :  0.3\n",
      "57  and  225 :  0.2\n",
      "57  and  360 :  0.2\n",
      "60  and  111 :  0.1\n",
      "60  and  182 :  0.1\n",
      "60  and  308 :  0.1\n",
      "60  and  336 :  0.1\n",
      "62  and  87 :  0.1\n",
      "62  and  113 :  0.1\n",
      "62  and  317 :  0.1\n",
      "62  and  372 :  0.1\n",
      "66  and  115 :  0.2\n",
      "66  and  254 :  0.4\n",
      "66  and  264 :  0.2\n",
      "66  and  339 :  0.2\n",
      "66  and  350 :  0.3\n",
      "66  and  371 :  0.2\n",
      "67  and  81 :  0.2\n",
      "67  and  228 :  0.2\n",
      "69  and  331 :  0.2\n",
      "70  and  72 :  0.2\n",
      "70  and  222 :  0.1\n",
      "70  and  319 :  0.1\n",
      "70  and  393 :  0.3\n",
      "71  and  182 :  0.1\n",
      "71  and  197 :  0.1\n",
      "71  and  226 :  0.1\n",
      "71  and  251 :  0.2\n",
      "71  and  253 :  0.2\n",
      "71  and  363 :  0.1\n",
      "72  and  222 :  0.1\n",
      "72  and  319 :  0.1\n",
      "72  and  393 :  0.2\n",
      "74  and  331 :  0.1\n",
      "75  and  76 :  1.0\n",
      "75  and  120 :  0.1\n",
      "76  and  120 :  0.1\n",
      "78  and  80 :  0.1\n",
      "78  and  340 :  0.1\n",
      "79  and  113 :  0.1\n",
      "80  and  85 :  0.1\n",
      "84  and  98 :  0.1\n",
      "84  and  103 :  0.1\n",
      "84  and  123 :  0.1\n",
      "84  and  137 :  0.1\n",
      "84  and  140 :  0.1\n",
      "84  and  144 :  0.1\n",
      "84  and  167 :  0.1\n",
      "84  and  186 :  0.1\n",
      "84  and  187 :  0.1\n",
      "84  and  200 :  0.1\n",
      "84  and  215 :  0.1\n",
      "84  and  226 :  0.1\n",
      "84  and  259 :  0.2\n",
      "84  and  357 :  0.1\n",
      "87  and  88 :  0.1\n",
      "87  and  113 :  0.1\n",
      "87  and  203 :  0.1\n",
      "87  and  206 :  0.1\n",
      "87  and  317 :  0.2\n",
      "87  and  326 :  0.1\n",
      "87  and  372 :  0.1\n",
      "88  and  90 :  0.3\n",
      "88  and  92 :  0.3\n",
      "88  and  125 :  0.3\n",
      "88  and  130 :  0.3\n",
      "88  and  134 :  0.2\n",
      "88  and  146 :  0.1\n",
      "88  and  149 :  0.2\n",
      "88  and  184 :  0.2\n",
      "88  and  192 :  0.2\n",
      "88  and  206 :  0.1\n",
      "88  and  225 :  0.2\n",
      "88  and  304 :  0.1\n",
      "88  and  310 :  0.1\n",
      "88  and  360 :  0.3\n",
      "90  and  92 :  0.5\n",
      "90  and  95 :  0.1\n",
      "90  and  125 :  0.4\n",
      "90  and  130 :  0.4\n",
      "90  and  134 :  0.2\n",
      "90  and  146 :  0.1\n",
      "90  and  149 :  0.2\n",
      "90  and  184 :  0.2\n",
      "90  and  192 :  0.4\n",
      "90  and  225 :  0.2\n",
      "90  and  360 :  0.4\n",
      "92  and  125 :  0.4\n",
      "92  and  130 :  0.4\n",
      "92  and  134 :  0.2\n",
      "92  and  146 :  0.1\n",
      "92  and  149 :  0.3\n",
      "92  and  184 :  0.2\n",
      "92  and  192 :  0.6\n",
      "92  and  225 :  0.2\n",
      "92  and  360 :  0.4\n",
      "95  and  108 :  0.1\n",
      "95  and  131 :  0.1\n",
      "95  and  193 :  0.3\n",
      "96  and  172 :  0.1\n",
      "97  and  131 :  0.2\n",
      "97  and  163 :  0.2\n",
      "98  and  103 :  0.1\n",
      "98  and  137 :  0.1\n",
      "98  and  140 :  0.2\n",
      "98  and  144 :  0.1\n",
      "98  and  178 :  0.1\n",
      "98  and  186 :  0.1\n",
      "98  and  187 :  0.1\n",
      "98  and  200 :  0.1\n",
      "98  and  215 :  0.2\n",
      "98  and  234 :  0.1\n",
      "98  and  259 :  0.1\n",
      "98  and  357 :  0.1\n",
      "101  and  170 :  0.1\n",
      "102  and  338 :  0.2\n",
      "103  and  137 :  0.1\n",
      "103  and  140 :  0.1\n",
      "103  and  144 :  0.1\n",
      "103  and  186 :  0.1\n",
      "103  and  187 :  0.1\n",
      "103  and  194 :  0.1\n",
      "103  and  200 :  0.1\n",
      "103  and  215 :  0.1\n",
      "103  and  259 :  0.1\n",
      "103  and  357 :  0.1\n",
      "104  and  183 :  0.1\n",
      "104  and  367 :  0.1\n",
      "105  and  305 :  0.1\n",
      "107  and  129 :  0.1\n",
      "107  and  130 :  0.1\n",
      "108  and  131 :  0.1\n",
      "111  and  182 :  0.1\n",
      "111  and  308 :  0.1\n",
      "111  and  336 :  0.1\n",
      "112  and  133 :  0.2\n",
      "112  and  261 :  0.1\n",
      "112  and  268 :  0.2\n",
      "113  and  317 :  0.1\n",
      "113  and  372 :  0.1\n",
      "114  and  306 :  0.1\n",
      "115  and  189 :  0.1\n",
      "115  and  254 :  0.2\n",
      "115  and  264 :  0.2\n",
      "115  and  339 :  0.2\n",
      "115  and  350 :  0.2\n",
      "115  and  371 :  0.2\n",
      "116  and  183 :  0.1\n",
      "116  and  206 :  0.1\n",
      "116  and  252 :  0.1\n",
      "119  and  120 :  0.1\n",
      "119  and  248 :  0.1\n",
      "123  and  167 :  0.1\n",
      "123  and  226 :  0.1\n",
      "123  and  259 :  0.1\n",
      "125  and  130 :  0.4\n",
      "125  and  134 :  0.2\n",
      "125  and  146 :  0.1\n",
      "125  and  149 :  0.2\n",
      "125  and  184 :  0.2\n",
      "125  and  192 :  0.3\n",
      "125  and  225 :  0.2\n",
      "125  and  360 :  0.3\n",
      "129  and  130 :  0.1\n",
      "129  and  222 :  0.1\n",
      "129  and  241 :  0.1\n",
      "130  and  134 :  0.2\n",
      "130  and  146 :  0.1\n",
      "130  and  149 :  0.2\n",
      "130  and  184 :  0.2\n",
      "130  and  192 :  0.3\n",
      "130  and  225 :  0.2\n",
      "130  and  241 :  0.1\n",
      "130  and  360 :  0.3\n",
      "131  and  163 :  0.2\n",
      "133  and  204 :  0.1\n",
      "133  and  253 :  0.1\n",
      "133  and  261 :  0.1\n",
      "133  and  268 :  0.1\n",
      "134  and  146 :  0.1\n",
      "134  and  149 :  0.3\n",
      "134  and  184 :  0.1\n",
      "134  and  187 :  0.5\n",
      "134  and  192 :  0.1\n",
      "134  and  225 :  0.1\n",
      "134  and  360 :  0.2\n",
      "136  and  145 :  0.2\n",
      "136  and  227 :  0.3\n",
      "136  and  228 :  0.3\n",
      "136  and  245 :  0.1\n",
      "136  and  396 :  0.1\n",
      "137  and  140 :  0.1\n",
      "137  and  144 :  0.1\n",
      "137  and  186 :  0.1\n",
      "137  and  187 :  0.1\n",
      "137  and  200 :  0.1\n",
      "137  and  215 :  0.1\n",
      "137  and  259 :  0.1\n",
      "137  and  357 :  0.1\n",
      "140  and  144 :  0.2\n",
      "140  and  178 :  0.1\n",
      "140  and  186 :  0.1\n",
      "140  and  187 :  0.1\n",
      "140  and  200 :  0.1\n",
      "140  and  215 :  0.2\n",
      "140  and  259 :  0.1\n",
      "140  and  357 :  0.1\n",
      "141  and  244 :  0.1\n",
      "141  and  336 :  0.2\n",
      "141  and  356 :  0.1\n",
      "144  and  186 :  0.1\n",
      "144  and  187 :  0.1\n",
      "144  and  200 :  0.1\n",
      "144  and  215 :  0.1\n",
      "144  and  242 :  0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144  and  259 :  0.1\n",
      "144  and  357 :  0.1\n",
      "144  and  386 :  0.2\n",
      "145  and  182 :  0.1\n",
      "145  and  204 :  0.1\n",
      "145  and  227 :  0.3\n",
      "145  and  228 :  0.2\n",
      "145  and  338 :  0.1\n",
      "145  and  396 :  0.1\n",
      "146  and  149 :  0.2\n",
      "146  and  184 :  0.1\n",
      "146  and  192 :  0.1\n",
      "146  and  225 :  0.1\n",
      "146  and  289 :  0.1\n",
      "146  and  360 :  0.1\n",
      "148  and  322 :  0.3\n",
      "148  and  395 :  0.1\n",
      "149  and  184 :  0.1\n",
      "149  and  192 :  0.2\n",
      "149  and  225 :  0.1\n",
      "149  and  360 :  0.2\n",
      "152  and  153 :  1.0\n",
      "154  and  157 :  0.1\n",
      "154  and  162 :  0.1\n",
      "154  and  182 :  0.1\n",
      "154  and  197 :  0.1\n",
      "154  and  226 :  0.1\n",
      "154  and  237 :  0.1\n",
      "154  and  245 :  0.1\n",
      "154  and  251 :  0.1\n",
      "154  and  253 :  0.1\n",
      "154  and  271 :  0.1\n",
      "154  and  274 :  0.1\n",
      "154  and  275 :  0.1\n",
      "154  and  281 :  0.1\n",
      "154  and  354 :  0.1\n",
      "154  and  358 :  0.1\n",
      "154  and  363 :  0.1\n",
      "157  and  162 :  0.1\n",
      "157  and  274 :  0.1\n",
      "157  and  275 :  0.1\n",
      "157  and  281 :  0.1\n",
      "161  and  304 :  0.1\n",
      "162  and  219 :  0.1\n",
      "162  and  274 :  0.1\n",
      "162  and  275 :  0.1\n",
      "162  and  281 :  0.1\n",
      "162  and  295 :  0.1\n",
      "162  and  373 :  0.1\n",
      "163  and  175 :  0.1\n",
      "163  and  221 :  0.1\n",
      "163  and  313 :  0.1\n",
      "165  and  170 :  0.1\n",
      "167  and  226 :  0.1\n",
      "167  and  259 :  0.1\n",
      "168  and  283 :  0.1\n",
      "172  and  252 :  0.1\n",
      "172  and  351 :  0.1\n",
      "173  and  352 :  0.3\n",
      "176  and  217 :  0.1\n",
      "176  and  318 :  0.2\n",
      "178  and  215 :  0.1\n",
      "178  and  234 :  0.2\n",
      "179  and  330 :  0.1\n",
      "179  and  345 :  0.2\n",
      "179  and  366 :  0.1\n",
      "179  and  385 :  0.1\n",
      "181  and  203 :  0.1\n",
      "181  and  317 :  0.1\n",
      "182  and  197 :  0.2\n",
      "182  and  226 :  0.1\n",
      "182  and  245 :  0.1\n",
      "182  and  251 :  0.1\n",
      "182  and  253 :  0.2\n",
      "182  and  308 :  0.1\n",
      "182  and  336 :  0.1\n",
      "182  and  354 :  0.1\n",
      "182  and  358 :  0.1\n",
      "182  and  363 :  0.1\n",
      "183  and  206 :  0.1\n",
      "183  and  252 :  0.1\n",
      "183  and  367 :  0.2\n",
      "184  and  192 :  0.2\n",
      "184  and  225 :  0.2\n",
      "184  and  360 :  0.2\n",
      "185  and  196 :  0.1\n",
      "185  and  206 :  0.1\n",
      "185  and  214 :  0.1\n",
      "186  and  187 :  0.1\n",
      "186  and  200 :  0.1\n",
      "186  and  215 :  0.1\n",
      "186  and  259 :  0.1\n",
      "186  and  357 :  0.1\n",
      "187  and  200 :  0.1\n",
      "187  and  215 :  0.1\n",
      "187  and  259 :  0.1\n",
      "187  and  357 :  0.1\n",
      "188  and  316 :  0.3\n",
      "189  and  225 :  0.1\n",
      "189  and  245 :  0.1\n",
      "189  and  270 :  0.1\n",
      "192  and  225 :  0.2\n",
      "192  and  360 :  0.3\n",
      "197  and  226 :  0.1\n",
      "197  and  245 :  0.1\n",
      "197  and  251 :  0.1\n",
      "197  and  253 :  0.2\n",
      "197  and  354 :  0.1\n",
      "197  and  358 :  0.1\n",
      "197  and  363 :  0.1\n",
      "198  and  296 :  0.1\n",
      "200  and  208 :  0.1\n",
      "200  and  215 :  0.1\n",
      "200  and  259 :  0.1\n",
      "200  and  357 :  0.1\n",
      "201  and  283 :  0.1\n",
      "202  and  239 :  0.1\n",
      "203  and  317 :  0.2\n",
      "203  and  326 :  0.1\n",
      "204  and  227 :  0.1\n",
      "204  and  253 :  0.1\n",
      "206  and  252 :  0.2\n",
      "206  and  305 :  0.1\n",
      "206  and  379 :  0.3\n",
      "211  and  216 :  0.1\n",
      "213  and  359 :  0.2\n",
      "214  and  387 :  0.2\n",
      "215  and  259 :  0.1\n",
      "215  and  357 :  0.1\n",
      "216  and  272 :  0.1\n",
      "217  and  318 :  0.1\n",
      "219  and  373 :  0.1\n",
      "221  and  294 :  0.1\n",
      "222  and  393 :  0.1\n",
      "225  and  270 :  0.1\n",
      "225  and  360 :  0.2\n",
      "226  and  245 :  0.1\n",
      "226  and  251 :  0.2\n",
      "226  and  253 :  0.1\n",
      "226  and  259 :  0.1\n",
      "226  and  354 :  0.1\n",
      "226  and  358 :  0.1\n",
      "226  and  363 :  0.1\n",
      "227  and  228 :  0.3\n",
      "227  and  245 :  0.1\n",
      "227  and  396 :  0.1\n",
      "228  and  245 :  0.1\n",
      "228  and  396 :  0.1\n",
      "232  and  235 :  0.2\n",
      "241  and  290 :  0.1\n",
      "242  and  386 :  0.3\n",
      "243  and  300 :  0.1\n",
      "245  and  251 :  0.1\n",
      "245  and  253 :  0.1\n",
      "245  and  354 :  0.1\n",
      "245  and  358 :  0.1\n",
      "245  and  363 :  0.1\n",
      "245  and  389 :  0.1\n",
      "246  and  273 :  0.1\n",
      "250  and  319 :  0.1\n",
      "251  and  253 :  0.1\n",
      "251  and  354 :  0.1\n",
      "251  and  358 :  0.1\n",
      "251  and  363 :  0.2\n",
      "252  and  351 :  0.1\n",
      "253  and  354 :  0.1\n",
      "253  and  358 :  0.1\n",
      "253  and  363 :  0.1\n",
      "254  and  264 :  0.2\n",
      "254  and  339 :  0.2\n",
      "254  and  350 :  0.3\n",
      "254  and  371 :  0.2\n",
      "256  and  373 :  0.1\n",
      "259  and  357 :  0.1\n",
      "261  and  268 :  0.1\n",
      "264  and  339 :  0.2\n",
      "264  and  350 :  0.2\n",
      "264  and  371 :  0.2\n",
      "267  and  287 :  0.1\n",
      "267  and  304 :  0.1\n",
      "269  and  325 :  0.1\n",
      "273  and  283 :  0.1\n",
      "274  and  275 :  0.1\n",
      "274  and  281 :  0.1\n",
      "275  and  281 :  0.1\n",
      "276  and  281 :  0.1\n",
      "280  and  358 :  0.1\n",
      "280  and  371 :  0.1\n",
      "284  and  387 :  0.1\n",
      "287  and  304 :  0.1\n",
      "300  and  386 :  0.2\n",
      "303  and  318 :  0.1\n",
      "303  and  363 :  0.1\n",
      "304  and  310 :  0.1\n",
      "305  and  379 :  0.1\n",
      "308  and  336 :  0.1\n",
      "317  and  324 :  0.1\n",
      "317  and  326 :  0.1\n",
      "317  and  361 :  0.1\n",
      "317  and  372 :  0.1\n",
      "317  and  374 :  0.2\n",
      "318  and  325 :  0.1\n",
      "319  and  393 :  0.1\n",
      "324  and  374 :  0.2\n",
      "326  and  372 :  0.1\n",
      "327  and  330 :  0.2\n",
      "330  and  345 :  0.1\n",
      "330  and  366 :  0.2\n",
      "330  and  385 :  0.1\n",
      "330  and  389 :  0.2\n",
      "331  and  382 :  0.1\n",
      "337  and  387 :  0.3\n",
      "339  and  350 :  0.2\n",
      "339  and  371 :  0.2\n",
      "345  and  366 :  0.1\n",
      "345  and  385 :  0.1\n",
      "350  and  371 :  0.2\n",
      "354  and  358 :  0.1\n",
      "354  and  363 :  0.1\n",
      "358  and  363 :  0.1\n",
      "358  and  371 :  0.1\n",
      "366  and  385 :  0.1\n",
      "366  and  389 :  0.1\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "for i in range (0, len(df)-1):\n",
    "    for j in range (i+1, len(df)):\n",
    "        sim = min_hash_sim(df.signature.iloc[i], df.signature.iloc[j]);\n",
    "        if sim >= threshold: \n",
    "            print(i,\" and \", j, \": \", sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH phase\n",
    "\n",
    "We set the elements per bnad and add all the possible candidate pairs to a set. \n",
    "To do this we iterate over all pairs exactly once, but we itare over the lists of signatures as well and also bandwise. This leads to an inneficient code, but it is ok for small number of documents (<500), like this test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(8, 44),\n",
       " (8, 134),\n",
       " (44, 134),\n",
       " (55, 136),\n",
       " (55, 227),\n",
       " (55, 228),\n",
       " (75, 76),\n",
       " (90, 92),\n",
       " (90, 125),\n",
       " (90, 130),\n",
       " (90, 192),\n",
       " (90, 360),\n",
       " (92, 125),\n",
       " (92, 130),\n",
       " (92, 192),\n",
       " (92, 360),\n",
       " (97, 131),\n",
       " (97, 163),\n",
       " (112, 133),\n",
       " (125, 130),\n",
       " (131, 163),\n",
       " (134, 187),\n",
       " (136, 227),\n",
       " (136, 228),\n",
       " (144, 242),\n",
       " (144, 386),\n",
       " (148, 322),\n",
       " (152, 153),\n",
       " (192, 360),\n",
       " (206, 252),\n",
       " (226, 251),\n",
       " (227, 228),\n",
       " (242, 386)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lsh implementation\n",
    "elem_per_band = 2\n",
    "candidate_pairs = set()\n",
    "\n",
    "for b in range (0, numhashes//elem_per_band):\n",
    "    for i in range (0, len(df)-1):\n",
    "        for j in range (i+1, len(df)):\n",
    "            s1 = 0\n",
    "            s2 = 0\n",
    "            for e in range(b*elem_per_band, b*elem_per_band+elem_per_band):\n",
    "                s1 += df.signature.iloc[i][e]\n",
    "                s2 += df.signature.iloc[j][e]\n",
    "            if (s1 == s2): \n",
    "                candidate_pairs.add((i, j))\n",
    "candidate_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Absolutely gorgeous and wonderful We will repeat for sure Thanks for the kindness        \n",
      " \n",
      "Yesterday I drive to the restaurant Areas do Seixo to enjoy the peace and praised the quality of the environment and flavors\n",
      "However I had not made a reservation while browsing the site after reading the Evases magazine about the reopening I did not get the idea that it was necessary\n",
      "Regards the chef Leonardo Pereira authorized an exception and we could have lunch\n",
      "There are no words to express the gratitude for the kindness\n",
      "And then it was a memorable dining experience  Since the care and education of employees the combination of flavors the friendliness of the chef Leonardo Pereira Who kindly presented us with a surprise dessert\n",
      "It is with great appreciation that mean that approx trip 700km worth of all the wonderful experience\n",
      "In this regard I must complement all the elements of your team            \n",
      "\n",
      "[876264128, 1003172853, 114275788, 218140582, 144069921, 636831237, 1123852149, 1245630026, 39415390, 12330435]\n",
      "[11032232, 4195109, 51482394, 13503072, 78706271, 138445147, 97227409, 8175355, 39415390, 12330435]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test example: take a pair from the canditate set\n",
    "signatures = next(iter(candidate_pairs))\n",
    "sig1, sig2 = signatures[0], signatures[1]\n",
    "\n",
    "#print the text\n",
    "print(df.Review.iloc[sig1])\n",
    "print(df.Review.iloc[sig2])\n",
    "print()\n",
    "#print the signatures\n",
    "print(df.signature.iloc[sig1])\n",
    "print(df.signature.iloc[sig2])\n",
    "\n",
    "#print the minhash similarity\n",
    "min_hash_sim(df.signature.iloc[sig1], df.signature.iloc[sig2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
