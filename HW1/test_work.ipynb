{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 3: '\t' expected after '\"'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everything from the weather staff food propert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We full enjoyed the place and facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks for the cidreira and madalenas tea at r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One dream Cozy  and comfortable Hotel  The bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel concept is hard to grasp They communicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  Everything from the weather staff food propert...\n",
       "1           We full enjoyed the place and facilities\n",
       "2  Thanks for the cidreira and madalenas tea at r...\n",
       "3  One dream Cozy  and comfortable Hotel  The bes...\n",
       "4  Hotel concept is hard to grasp They communicat..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('dataset-CalheirosMoroRita-2017.csv',  error_bad_lines=False, engine='python', sep=\"\\t\")\n",
    "df['Review'] = df['Review'].str.replace(r'[^\\w\\s]+', '')\n",
    "documents = df\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shingling phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shingling articles...\n",
      "\n",
      "Total number of shingles 17343\n",
      "\n",
      "Shingled 402 docs \n",
      "\n",
      "Average shingles per doc: 43.14\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import binascii\n",
    "import re\n",
    "\n",
    "print(\"Shingling articles...\")\n",
    "print()\n",
    "\n",
    "#initializing variables\n",
    "shingle_size = 5\n",
    "docsAsShingleSets = {}\n",
    "docNames = []\n",
    "totalShingles = 0\n",
    "shingleNo = 0\n",
    "\n",
    "# loop through all the documents\n",
    "for index, row in documents.iterrows():\n",
    "    \n",
    "    # Read all of the words (they are all on one line)\n",
    "    review = row.iloc[0]\n",
    "    words = re.sub(\"[^\\w]\", \" \",  review).split()\n",
    "\n",
    "    # Retrieve the article ID\n",
    "    docID = index\n",
    "\n",
    "    # Maintain a list of all document IDs.\n",
    "    docNames.append(docID)\n",
    "\n",
    "    # 'shinglesInDoc' will hold all of the unique shingles present in the\n",
    "    # current document. If a shingle ID occurs multiple times in the document,\n",
    "    # it will only appear once in the set.\n",
    "\n",
    "  \n",
    "    # keep word shingles\n",
    "    shinglesInDocWords = set()\n",
    "\n",
    "    # keep hashed shingles\n",
    "    shinglesInDocInts = set()\n",
    "\n",
    "    shingle = []\n",
    "    # For each word in the document...\n",
    "    for index in range(len(words) - shingle_size + 1):\n",
    "        # Construct the shingle text by combining k words together.\n",
    "        shingle = words[index:index + shingle_size]\n",
    "        shingle = ' '.join(shingle)\n",
    "        #print(shingle)\n",
    "        \n",
    "        # Hash the shingle to a 32-bit integer.\n",
    "        crc = binascii.crc32(shingle.encode(\"utf-8\")) & 0xffffffff\n",
    "\n",
    "        if shingle not in shinglesInDocWords:\n",
    "            shinglesInDocWords.add(shingle)\n",
    "        # Add the hash value to the list of shingles for the current document.\n",
    "        # Note that set objects will only add the value to the set if the set\n",
    "        # doesn't already contain it.\n",
    "\n",
    "        if crc not in shinglesInDocInts:\n",
    "            shinglesInDocInts.add(crc)\n",
    "            # Count the number of shingles across all documents.\n",
    "            shingleNo = shingleNo + 1\n",
    "        \n",
    "        else:\n",
    "            del shingle\n",
    "            index = index - 1\n",
    "\n",
    "    # Store the completed list of shingles for this document in the dictionary.\n",
    "    docsAsShingleSets[docID] = shinglesInDocInts\n",
    "\n",
    "totalShingles = shingleNo\n",
    "\n",
    "print('Total number of shingles', shingleNo)\n",
    "# Report how long shingling took.\n",
    "print('\\nShingled ' + str(len(docsAsShingleSets)) + ' docs ')\n",
    "print('\\nAverage shingles per doc: %.2f' % (shingleNo / len(docsAsShingleSets)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinHash phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define virtual Triangle matrices to hold the similarity values. For storing\n",
    "# similarities between pairs, we only need roughly half the elements of a full\n",
    "# matrix. Using a triangle matrix requires less than half the memory of a full\n",
    "# matrix. Using a triangle matrix requires less than half the memory of a full\n",
    "# matrix, and can protect the programmer from inadvertently accessing one of\n",
    "# the empty/invalid cells of a full matrix.\n",
    "\n",
    "# Calculate the number of elements needed in our triangle matrix\n",
    "numElems = int(len(docsAsShingleSets) * (len(docsAsShingleSets) - 1) / 2)\n",
    "\n",
    "# Initialize two empty lists to store the similarity values.\n",
    "# 'JSim' will be for the actual Jaccard Similarity values.\n",
    "# 'estJSim' will be for the estimated Jaccard Similarities found by comparing\n",
    "# the MinHash signatures.\n",
    "JSim = [0 for x in range(numElems)]\n",
    "estJSim = [0 for x in range(numElems)]\n",
    "\n",
    "\n",
    "# Define a function to map a 2D matrix coordinate into a 1D index.\n",
    "def getTriangleIndex(i, j):\n",
    "    # If i == j that's an error.\n",
    "    if i == j:\n",
    "        sys.stderr.write(\"Can't access triangle matrix with i == j\")\n",
    "        sys.exit(1)\n",
    "    # If j < i just swap the values.\n",
    "    if j < i:\n",
    "        temp = i\n",
    "        i = j\n",
    "        j = temp\n",
    "\n",
    "    # Calculate the index within the triangular array.\n",
    "    # This fancy indexing scheme is taken from pg. 211 of:\n",
    "    # http://infolab.stanford.edu/~ullman/mmds/ch6.pdf\n",
    "    # But I adapted it for a 0-based index.\n",
    "    # Note: The division by two should not truncate, it\n",
    "    #       needs to be a float.\n",
    "    k = int(i * (len(docsAsShingleSets) - (i + 1) / 2.0) + j - i) - 1\n",
    "\n",
    "    return k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: overflow encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "#print '\\nGenerating random hash functions...'\n",
    "\n",
    "numHashes = 10\n",
    "\n",
    "# Record the maximum shingle ID that we assigned.\n",
    "maxShingleID = 2**32-1\n",
    "\n",
    "# We need the next largest prime number above 'maxShingleID'.\n",
    "# I looked this value up here: \n",
    "# http://compoasso.free.fr/primelistweb/page/prime/liste_online_en.php\n",
    "nextPrime = 4294967311\n",
    "\n",
    "# Our random hash function will take the form of:\n",
    "#   h(x) = (a*x + b) % c\n",
    "# Where 'x' is the input value, 'a' and 'b' are random coefficients, and 'c' is\n",
    "# a prime number just greater than maxShingleID.\n",
    "\n",
    "\n",
    "# For each of the 'numHashes' hash functions, generate a different coefficient 'a' and 'b'.   \n",
    "coeffA = np.random.randint(10, size=numHashes)\n",
    "coeffB = np.random.randint(10, size=numHashes)\n",
    "\n",
    "#print '\\nGenerating MinHash signatures for all documents...'\n",
    "\n",
    "# List of documents represented as signature vectors\n",
    "signatures = []\n",
    "\n",
    "# Rather than generating a random permutation of all possible shingles, \n",
    "# we'll just hash the IDs of the shingles that are *actually in the document*,\n",
    "# then take the lowest resulting hash code value. This corresponds to the index \n",
    "# of the first shingle that you would have encountered in the random order.\n",
    "\n",
    "# For each document...\n",
    "for docID in docNames:\n",
    "  \n",
    "  # Get the shingle set for this document.\n",
    "  shingleIDSet = docsAsShingleSets[docID]\n",
    "  \n",
    "  # The resulting minhash signature for this document. \n",
    "  signature = []\n",
    "  \n",
    "  # For each of the random hash functions...\n",
    "  for i in range(0, numHashes):\n",
    "    \n",
    "    # For each of the shingles actually in the document, calculate its hash code\n",
    "    # using hash function 'i'. \n",
    "    \n",
    "    # Track the lowest hash ID seen. Initialize 'minHashCode' to be greater than\n",
    "    # the maximum possible value output by the hash.\n",
    "    minHashCode = nextPrime + 1\n",
    "    \n",
    "    # For each shingle in the document...\n",
    "    for shingleID in shingleIDSet:\n",
    "      # Evaluate the hash function.\n",
    "      hashCode = (coeffA[i] * shingleID + coeffB[i]) % nextPrime \n",
    "      \n",
    "      # Track the lowest hash code seen.\n",
    "      if hashCode < minHashCode:\n",
    "        minHashCode = hashCode\n",
    "\n",
    "    # Add the smallest hash code value as component number 'i' of the signature.\n",
    "    signature.append(minHashCode)\n",
    "  \n",
    "  # Store the MinHash signature for this document.\n",
    "  signatures.append(signature)\n",
    "\n",
    "       \n",
    "#print \"\\nGenerating MinHash signatures took %.2fsec\" % elapsed  \n",
    "#print(signatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDocs = documents.size\n",
    "\n",
    "# Creates a N x N matrix initialized to 0.\n",
    "\n",
    "# Time this step.\n",
    "t0 = time.time()\n",
    "\n",
    "# For each of the test documents...\n",
    "for i in range(0, numDocs):\n",
    "  # Get the MinHash signature for document i.\n",
    "  signature1 = signatures[i]\n",
    "    \n",
    "  # For each of the other test documents...\n",
    "  for j in range(i + 1, numDocs):\n",
    "    \n",
    "    # Get the MinHash signature for document j.\n",
    "    signature2 = signatures[j]\n",
    "    \n",
    "    count = 0\n",
    "    # Count the number of positions in the minhash signature which are equal.\n",
    "    for k in range(0, numHashes):\n",
    "      count = count + (signature1[k] == signature2[k])\n",
    "    \n",
    "    # Record the percentage of positions which matched.    \n",
    "    estJSim[getTriangleIndex(i, j)] = (count / numHashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = len(docsAsShingleSets[0])\n",
    "# For every document pair...\n",
    "i = 90\n",
    "\n",
    "# Print progress every 100 documents.\n",
    "if (i % 100) == 0:\n",
    "    print(\"  (\" + str(i) + \" / \" + str(len(docsAsShingleSets)) + \")\")\n",
    "\n",
    "# Retrieve the set of shingles for document i.\n",
    "s1 = docsAsShingleSets[docNames[i]]\n",
    "neighbors_of_given_documentSHINGLES = {}\n",
    "\n",
    "for j in range(0, len(docsAsShingleSets)):\n",
    "    if j != i:\n",
    "        # Retrieve the set of shingles for document j.\n",
    "        s2 = docsAsShingleSets[docNames[j]]\n",
    "\n",
    "        # Calculate and store the actual Jaccard similarity.\n",
    "        JSim[getTriangleIndex(i, j)] = (len(s1.intersection(s2)) / float(len(s1.union(s2))))\n",
    "        percsimilarity = JSim[getTriangleIndex(i, j)] * 100\n",
    "        if (percsimilarity > 0):\n",
    "            # Print out the match and similarity values with pretty spacing.\n",
    "            print(\"  %5s --> %5s   %.2f%s   \" % (docNames[i], docNames[j], percsimilarity, '%'))\n",
    "            neighbors_of_given_documentSHINGLES[j] = percsimilarity\n",
    "\n",
    "sorted_neigborsSHINGLES = sorted(neighbors_of_given_documentSHINGLES.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#print 'Comparing Shingles ...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
